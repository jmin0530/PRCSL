/workspace/ACCV_2024/PRCSL/src/approach/der.py:104: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  batch_exemplars.logits[i] = torch.tensor(lgt).clone().detach()
Traceback (most recent call last):
  File "/workspace/ACCV_2024/PRCSL/src/main.py", line 295, in <module>
    
  File "/workspace/ACCV_2024/PRCSL/src/main.py", line 243, in main
    if args.approach != 'der':
  File "/workspace/ACCV_2024/PRCSL/src/approach/incremental_learning.py", line 55, in train
    self.train_loop(t, trn_loader, val_loader)
  File "/workspace/ACCV_2024/PRCSL/src/approach/der.py", line 66, in train_loop
    super().train_loop(t, trn_loader, val_loader)
  File "/workspace/ACCV_2024/PRCSL/src/approach/incremental_learning.py", line 72, in train_loop
    self.train_epoch(t, trn_loader)
  File "/workspace/ACCV_2024/PRCSL/src/approach/der.py", line 117, in train_epoch
    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clipgrad)
  File "/opt/conda/envs/prcsl/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py", line 36, in clip_grad_norm_
    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)
  File "/opt/conda/envs/prcsl/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py", line 36, in <listcomp>
    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)
  File "/opt/conda/envs/prcsl/lib/python3.8/site-packages/torch/functional.py", line 1293, in norm
    return _VF.norm(input, p, dim=_dim, keepdim=keepdim)  # type: ignore
KeyboardInterrupt
